- mine the absolute fck out of video explainers and tutorials. this is RLHF for web agents because the people recording things do things like “oops” and there’s time codes aligning with what they just did, etc.
- Develop a comprehensive data engineering and research pipeline to systematically extract instructional video content and corresponding time-aligned actions. Leveraging these richly annotated recordings enables robust RLHF datasets for web agents, capturing natural corrections and contextual behaviors. Emphasizing those corrective moments and added nuance helps the model notice its own actions rather than simply learning to err and then fix, even if that distinction may be minor for now.
